{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "- [Pytorch](#torch)\n",
    "- [Installation](#install)\n",
    "- [Tensors](#tensors)\n",
    "- [Tensors operations and gradients](#grad)\n",
    "- [Interoperability with Numpy](#numpy)\n",
    "\n",
    "- [Interesting torch functions](#functions)\n",
    "    - [torch.Tensor.normal_()](#function1)\n",
    "    - [torch.split()](#function2)\n",
    "    - [torch.det()](#function3)\n",
    "    - [torch.pow()](#function4)\n",
    "    - [torch.Tensor.repeat()](#function5)\n",
    "    \n",
    "- [Reference Links](#reference)\n",
    "\n",
    "<div id='xx' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='torch' />\n",
    "\n",
    "## Pytorch basics\n",
    "\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR). It is free and open-source software released under the Modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\n",
    "\n",
    "PyTorch provides two high-level features:\n",
    "\n",
    "- Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU).\n",
    "- Deep neural networks built on a tape-based automatic differentiation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='install' />\n",
    "\n",
    "## Installation\n",
    "\n",
    "Visit the pytorch oficial [website](https://pytorch.org/get-started/locally/#mac-anaconda) for more info.\n",
    "\n",
    "- OS: Linux, Package: Pip and CUDA version 10.2\n",
    "\n",
    "`\n",
    "pip install torch torchvision\n",
    "`\n",
    "\n",
    "- OS: Linux, Package: Pip and NO CUDA (cpu)\n",
    "\n",
    "`\n",
    "pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "`\n",
    "\n",
    "- OS: Linux, Package: Conda and NO CUDA (cpu)\n",
    "\n",
    "`\n",
    "conda install pytorch torchvision cpuonly -c pytorch\n",
    "`\n",
    "\n",
    "- OS: Linux, Package: Conda and CUDA version 10.2\n",
    "\n",
    "`\n",
    "conda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='tensors' />\n",
    "\n",
    "## Tensors\n",
    "\n",
    "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-dimensional array. Let's create a tensor with a single number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating point number. We can verify this by checking the `dtype` attribute of our tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try creating slightly more complex tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "t3 = torch.tensor([[5., 6], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[15., 16., 17.],\n",
       "         [17., 18., 19.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-dimensional array\n",
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can have any number of dimensions, and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t3)\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11., 12., 13.],\n",
      "         [13., 14., 15.]],\n",
      "\n",
      "        [[15., 16., 17.],\n",
      "         [17., 18., 19.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t4)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='grad' />\n",
    "\n",
    "## Tensor operations and gradients\n",
    "\n",
    "We can combine tensors with the usual arithmetic operations. Let's look an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created 3 tensors `x`, `w` and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment. \n",
    "\n",
    "Let's create a new tensor `y` by combining these tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch special is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. To compute the derivatives, we can call the `.backward` method on our result `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivates of `y` w.r.t the input tensors are stored in the `.grad` property of the respective tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print(\"dy/dx:\", x.grad)\n",
    "print(\"dy/dw:\", w.grad)\n",
    "print(\"dy/db:\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `dy/dw` has the same value as `x` i.e. `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None`, because `x` doesn't have `requires_grad` set to `True`. \n",
    "\n",
    "The \"grad\" in `w.grad` stands for gradient, which is another term for derivative, used mainly when dealing with matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='numpy' />\n",
    "\n",
    "## Interoperability with Numpy\n",
    "\n",
    "[Numpy](http://www.numpy.org/) is a popular open source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays, and has a large ecosystem of supporting libraries:\n",
    "\n",
    "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
    "* [OpenCV](https://opencv.org/) for image and video processing\n",
    "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
    "\n",
    "Instead of reinventing the wheel, PyTorch interoperates really well with Numpy to leverage its existing ecosystem of tools and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we create an array in Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the numpy array and torch tensor have similar data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eq() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f00546b3e2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!)\n"
     ]
    }
   ],
   "source": [
    "z == x, z == y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interoperability between PyTorch and Numpy is really important because most datasets you'll work with will likely be read and preprocessed as Numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='functions' />\n",
    "\n",
    "## Interesting torch functions\n",
    "\n",
    "Lets take an overview of the following functions:\n",
    "\n",
    "- torch.Tensor.normal_()\n",
    "- torch.split()\n",
    "- torch.det()\n",
    "- torch.pow()\n",
    "- torch.Tensor.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='function1' />\n",
    "\n",
    "### Function 1 - normal_(mean=0, std=1, *, generator=None) → Tensor\n",
    "\n",
    "This function replaces the values in a given tensor with elements sampled from the normal distribution with a given mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0118,  0.4272],\n",
       "        [ 0.5719, -1.5410]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "my_tensor = torch.tensor([[1, 2], [3, 4.]])\n",
    "my_tensor.normal_(mean=0, std=1, generator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6172,  1.3737, -0.1046],\n",
       "        [ 1.9306,  1.1202, -0.0266],\n",
       "        [-1.2480, -1.1840,  2.3847]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "identity = torch.eye(3)\n",
    "identity.normal_(mean=0, std=1, generator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9276, -0.0280, -0.9658,  0.9420],\n",
       "        [ 0.8854,  0.1634, -1.0538,  0.1228],\n",
       "        [ 0.7828, -0.0404,  0.0268, -0.3090],\n",
       "        [ 0.2695, -0.4206,  0.4718, -0.2262]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "ones = torch.ones((4,4))\n",
    "ones.normal_(mean=0, std=1, generator=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='function2' />\n",
    "\n",
    "### Function 2 - torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\n",
    "Splits the tensor into chunks. Each chunk is a view of the original tensor.\n",
    "\n",
    "If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.\n",
    "\n",
    "If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks with sizes in dim according to split_size_or_sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.]]), tensor([[3., 4.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "my_tensor = torch.tensor([[1, 2], [3, 4.]])\n",
    "my_split = torch.split(my_tensor, 1, dim=0)\n",
    "print(type(my_split))\n",
    "my_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.]]),\n",
       " tensor([[0., 0., 1.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "identity = torch.eye(3)\n",
    "torch.split(identity, 2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "ones = torch.ones((4,4))\n",
    "torch.split(ones, 2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='function3' />\n",
    "\n",
    "### Function 3 - torch.det(input)\n",
    "\n",
    "Calculates determinant of a square matrix or batches of square matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.0000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "my_tensor = torch.tensor([[1, 2], [3, 4.]])\n",
    "my_det = torch.det(my_tensor)\n",
    "print(type(my_det))\n",
    "my_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "identity = torch.eye(3)\n",
    "torch.det(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "ones = torch.ones((4,4))\n",
    "torch.det(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='function4' />\n",
    "\n",
    "### Function 4 - torch.pow(input, exponent, out=None)\n",
    "\n",
    "Takes the power of each element in input with exponent and returns a tensor with the result. Exponent can be either a single float number or a Tensor with the same number of elements as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   4.],\n",
       "        [ 27., 256.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "my_tensor = torch.tensor([[1, 2], [3, 4.]])\n",
    "my_pow = torch.pow(my_tensor, my_tensor, out=None)\n",
    "print(type(my_pow))\n",
    "my_pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "identity = torch.eye(3)\n",
    "torch.pow(identity, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "# Take care with the factor 2 times matrix\n",
    "# Finally we expect 2^0 = 1\n",
    "\n",
    "ones = 2 * torch.ones((4,4))\n",
    "torch.pow(ones, 0, out=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='function5' />\n",
    "\n",
    "### Function 5 - repeat(*sizes)\n",
    "\n",
    "Repeats this tensor along the specified dimensions. Unlike expand(), this function copies the tensor’s data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[1., 2., 1., 2.],\n",
      "        [3., 4., 3., 4.],\n",
      "        [1., 2., 1., 2.],\n",
      "        [3., 4., 3., 4.],\n",
      "        [1., 2., 1., 2.],\n",
      "        [3., 4., 3., 4.],\n",
      "        [1., 2., 1., 2.],\n",
      "        [3., 4., 3., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "my_tensor = torch.tensor([[1, 2], [3, 4.]])\n",
    "my_rep = my_tensor.repeat(4, 2)\n",
    "print(type(my_rep))\n",
    "print(my_rep)\n",
    "my_rep.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "identity = torch.eye(3)\n",
    "identity.repeat(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 12])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "\n",
    "ones = 2 * torch.ones((4,4))\n",
    "my_rep = ones.repeat(2, 2, 3)\n",
    "print(my_rep)\n",
    "my_rep.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='reference' />\n",
    "\n",
    "## Reference Links\n",
    "\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
