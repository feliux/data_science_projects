{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data y Machine Learning para clasificación de galaxias\n",
    "\n",
    "- [Docker - Spark](#all-spark)\n",
    "    - [Jupyter Docker Stacks](#jds)\n",
    "- [Dataset de imágenes galácticas](#imagenes)\n",
    "    - [Script de imágenes](#script)\n",
    "\n",
    "    \n",
    "<div id='xx' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='all-spark' />\n",
    "\n",
    "## Docker - Spark\n",
    "\n",
    "En este punto del proyecto vamos a hacer un resumen de lo que hemos hecho hasta el momento:\n",
    "\n",
    "- Configuración del entorno de trabajo Cloudera.\n",
    "- Descarga da datos: dataset de parámetros y GalaxyZoo.\n",
    "- Almacenamiento en HDFS.\n",
    "- Almacenamiento en HIVE.\n",
    "- Consultas a través de HUE y ejemplo de análisis usando SPARK.\n",
    "\n",
    "El trabajo que nos queda por llevar a cabo sería el siguiente:\n",
    "\n",
    "- Desarrollo de script para descarga y procesamiento de imágenes.\n",
    "- Desarrollo de algoritmos de clasificación (machine learning).\n",
    "\n",
    "Sin embargo, nos hemos encontrado con una dificultad técnica durante la ejecución de éstos dos últimos apartados y que tiene relación con los requisitos de memoria RAM de nuestro entorno Cloudera. Hasta el momento nuestro contenedor Cloudera consume aproximadamente unos 10GB de memoria RAM sobre una máquina de 16GB de RAM. En el momento en el que intentamos cargar en memoria los datos de las imágenes y usar este dataset para entrenar nuestros modelos de machine learning nos encontramos con un error JAVA que nos indica que no tenemos suficiente memoria alojada en nuestro clúster (recordemos que nuestro entorno es standalone) para concluir con los jobs de SPARK. Dada la imposibilidad de llevar a cabo el entrenamiento de un modelo en Cloudera y debido a las insuficiencias técnicas descritas, hemos considerado la posibilidad de trasladar nuestro posterior trabajo a otro entorno que nos permita concluir con nuestro proyecto. El entorno elegido es un contenedor basado en las imágenes que ofece Jupyter Labs: [Jupyter Docker Stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "<div id='jds' />\n",
    "\n",
    "### Jupyter Docker Stacks\n",
    "\n",
    "Jupyter Docker Stacks consiste en una serie de imágenes Docker ya preparadas con un conjunto de aplicaciones y herramientas de computación. En especial resultan muy útiles durante el día a día de todo data scientist ya que contienen el stack típico de herramientas que suele necesitar. Por lo tanto, para el desarrollo de esta segunda parte de nuestro proyecto, y con la idea de seguir trabajando con SPARK, hemos decidido descargar la imagen [jupyter/all-spark-notebook](https://hub.docker.com/r/jupyter/all-spark-notebook/). Con las siguientes instrucciones tenemos nuestro entorno ya listo para trabajar:\n",
    "\n",
    "`\n",
    "$ docker pull jupyter/all-spark-notebook\n",
    "$ docker run -d --name spark -p 8888:8888 -v /home/<user>/cloudera:/home/jovyan/work jupyter/all-spark-notebook:latest\n",
    "`\n",
    "\n",
    "Así tenemos un contenedor llamado *spark* con nuestros *notebooks jupyter* accesibles en el puerto 8888 y con un volumen persistente que será nuestro directorio de trabajo. Para acceder a nuestro laboratorio tecleamos en consola y pegamos en nuestro navegador la url devuelta:\n",
    "\n",
    "`\n",
    "$ docker exec -t spark jupyter-notebook list\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='imagenes' />\n",
    "\n",
    "## Dataset de imágenes galácticas\n",
    "\n",
    "Tal como hicimos en el apartado de *Descarga de datos: Dataset GalaxyZoo*, procedemos a la descarga en nuestro nuevo entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://galaxy-zoo-1.s3.amazonaws.com/GalaxyZoo1_DR_table2.csv.zip\n",
    "!unzip GalaxyZoo1_DR_table2.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente [enlace](https://data.galaxyzoo.org/) tenemos toda la información sobre el dataset descargado, así como algunos artículos publicados sobre el proyecto *GalaxyZoo* y *SDSS*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mv GalaxyZoo1_DR_table2.csv data\n",
    "!cat data/GalaxyZoo1_DR_table2.csv | head -n3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del conjunto de variables con las que cuenta nuestro dataset nos interesan solo las siguientes (y cuyo significado ya hemos explicado con anterioridad): OBJID, RA, DEC, SPIRAL, ELLIPTICAL, UNCERTAIN. Serán estas variables las que usaremos para descargar las imágenes y construir nuestro dataset de entrenamiento.\n",
    "\n",
    "<div id='script' />\n",
    "\n",
    "### Script de imágenes\n",
    "\n",
    "Para descargar las imágenes recurriremos a la siguiente [web](https://skyserver.sdss.org/dr14/en/tools/chart/listinfo.aspx) del proyecto *SDSS*. Seleccionando el nombre y los parámetros de nuestra imagen podemos visualizar un conjunto de imágenes del *DataRelease 14*. Nosotros automatizaremos el proceso de descarga y procesado mediante el siguiente script que ya hemos explicado anteriormente. En resumen:\n",
    "\n",
    "- Descargamos 10000 imágenes de tamaño `64x64` en base al dataset de *GalaxyZoo*.\n",
    "\n",
    "\n",
    "- Cargamos las imágenes y las transformamos a escala de grises.\n",
    "\n",
    "\n",
    "- Construimos un vector con los píxeles de dichas imágenes.\n",
    "\n",
    "\n",
    "- Añadimos el `drobjid` y el `target` a dicho vector. El `target` lo construimos en base a la función `our_target()`, a la cual pasamos los valores consecutivos `uncertain+spiral+elliptical` del dataset *GalaxyZoo* como string y que en función de su valor (en binario) hacemos corresponder la clase/tipo de galaxia.\n",
    "\n",
    "\n",
    "    - uncertain+spiral+elliptical = 100 -> target = 0 -> clase = incierto\n",
    "    - uncertain+spiral+elliptical = 001 -> target = 1 -> clase = elíptica\n",
    "    - uncertain+spiral+elliptical = 010 -> target = 2 -> clase = espiral\n",
    "    \n",
    "    \n",
    "- Construimos un dataset que contiene las siguientes variables:\n",
    "\n",
    "    - drobjid: identificador del objeto.\n",
    "    - target: clase del objeto.\n",
    "    - F0 a F4095: correspondiente al vector de 4095 atributos de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir image-galaxyzoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "# Función para seleccionar la clase: 0 incierto, 1 elíptica, 2 espiral\n",
    "def our_target(string):\n",
    "    target = int(str(string), 2)\n",
    "    if target == 4:\n",
    "        target -= 4\n",
    "    return target\n",
    "\n",
    "# Contador de tiempo\n",
    "start = time()\n",
    "\n",
    "# Tamaño de las imágenes\n",
    "width, height = str(60), str(60)\n",
    "\n",
    "# Semilla\n",
    "random.seed(30)\n",
    "\n",
    "# Data\n",
    "name = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"1\" -d \",\" | awk 'NR > 1'\n",
    "ra = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"2\" -d \",\" | awk 'NR > 1'\n",
    "dec = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"3\" -d \",\" | awk 'NR > 1'\n",
    "spiral = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"14\" -d \",\" | awk 'NR > 1'\n",
    "elliptical = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"15\" -d \",\" | awk 'NR > 1'\n",
    "uncertain = !cat data/GalaxyZoo1_DR_table2.csv | cut -f \"16\" -d \",\" | awk 'NR > 1'\n",
    "\n",
    "# Seleccionaremios un conjunto de datos balanceados: 4000 spiral, 4000 elliptical, 2000 uncertain (40+40+20)\n",
    "# Índices que contienen \"1\"\n",
    "spiral_index = [i for i, e in enumerate(spiral) if e == \"1\"]\n",
    "elliptical_index = [i for i, e in enumerate(elliptical) if e == \"1\"]\n",
    "uncertain_index = [i for i, e in enumerate(uncertain) if e == \"1\"]\n",
    "\n",
    "# Selección aleatoria 40+40+20\n",
    "spiral_choices = random.choices(spiral_index, k=4000)\n",
    "elliptical_choices = random.choices(elliptical_index, k=4000)\n",
    "uncertain_choices = random.choices(uncertain_index, k=2000)\n",
    "\n",
    "# Construimos vector que contiene los índices de las imágenes que cumplen la condición 40+40+20\n",
    "index = [spiral_choices, elliptical_choices, uncertain_choices]\n",
    "index = [p for q in index for p in q]\n",
    "\n",
    "print(\"Número de filas dataset GalaxyZoo: \", len(name))\n",
    "\n",
    "# Contador de imágenes\n",
    "j = 1\n",
    "\n",
    "for i in index:\n",
    "    # Descarga de imagen\n",
    "    url_image = \"http://skyserver.sdss.org/dr14/SkyServerWS/ImgCutout/getjpeg?TaskName=Skyserver.Chart.List&ra=\"\\\n",
    "                +ra[i]+\"&dec=\"+dec[i]+\"&scale=0.4&width=\"+width+\"&height=\"+height+\"&opt=\"\n",
    "    \n",
    "    local_name = \"image-galaxyzoo/\" + name[i] + \".png\"\n",
    "    image = requests.get(url_image).content\n",
    "    \n",
    "    with open(local_name, 'wb') as png:\n",
    "        png.write(image)\n",
    "    \n",
    "    # Construimos target\n",
    "    target = our_target(uncertain[i]+spiral[i]+elliptical[i])\n",
    "    # Carga imagen a gris   \n",
    "    image_gray = cv2.imread(local_name, 0)\n",
    "    # Procesamiento imagen a vector\n",
    "    image_vector = np.reshape(image_gray, -1) / 255\n",
    "    # Construimos vector id, target, F0...\n",
    "    image_vector = image_vector.tolist()\n",
    "    image_vector.insert(0, target)\n",
    "    image_vector.insert(0, name[i])\n",
    "    \n",
    "    print(j, \"imágenes procesadas de\", len(name)-1)\n",
    "    \n",
    "    # Construcción dataset\n",
    "    with open('data/T_F_DR14_ZooSpec_10000.csv', mode='a+', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        if j == 1:\n",
    "            header = [str(\"F\") + str(x) for x in range(0, image_gray.size)]\n",
    "            header.insert(0, \"target\")\n",
    "            header.insert(0, \"dr7objid\")\n",
    "            writer.writerow(header)\n",
    "            \n",
    "        writer.writerow(image_vector)\n",
    "    j += 1\n",
    "    \n",
    "print(f\"Tiempo de ejecución: {(time() - start) / 60} (min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado de la descarga, tenemos un directorio `data` que contiene el dataset de *GalaxyZoo* y nuestro dataset de features *T_F_DR14_ZooSpec_10000.csv*. Además, en el directorio `image-galaxyzoo` tenemos 10000 imágenes de galaxias en formato `.png`: 4000 imágenes corresponden a la clase espiral, otras 4000 a la clase elíptica mientras que el resto (2000) corresponde a imágenes no clasificadas (incierto).\n",
    "\n",
    "Aunque la descarga la hemos hecho en nuestro nuevo entorno SPARK, el procedimiento sobre el entorno Cloudera sería exactamente el mismo con el único detalle de que nuestros datos quedarían guardado en HDFS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
