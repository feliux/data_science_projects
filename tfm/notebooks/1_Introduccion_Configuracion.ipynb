{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data y Machine Learning para clasificación de galaxias\n",
    "\n",
    "- [Introducción](#intro)\n",
    "    - [Astronomía y Big Data](#astro)\n",
    "    - [Las Galaxias](#galaxias)\n",
    "        - [Galaxias elípticas](#e07)\n",
    "        - [Galaxias lenticulares](#s0)\n",
    "        - [Galaxias espirales](#sa)\n",
    "        - [Galaxias espirales barradas](#sb0/ad)\n",
    "        - [Galaxias espirales intermedias](#sab0)\n",
    "        - [Galaxias irregulares](#irr)\n",
    "    - [GalaxyZoo](#zoo)\n",
    "    - [Sloan Digital Sky Survey](#sdss)\n",
    "- [Herramientas Cloudera](#herramientas)\n",
    "- [Configuración Cloudera](#conf)\n",
    "    - [Imagen y contenedor Docker](#docker)\n",
    "    - [Instalación de paquetes](#pkt)\n",
    "        - [wget](#wget)\n",
    "        - [Cloudera Manager](#manager)\n",
    "        - [Anaconda](#anaconda)\n",
    "        - [Java 8 JDK](#java8)\n",
    "        - [Spark2](#spark2)\n",
    "\n",
    "    \n",
    "<div id='xx' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Nuestro Universo está poblado por miles de millones de galaxias y cada una de ellas formada por miles de millones de estrellas. Los telescopios, situados tanto en satélites como en La Tierra, observan el cielo y toman una enorme cantidad de fotos digitales que luego los científicos estudian para entender cómo nacen las galaxias, cómo interaccionan entre ellas, cómo el Universo en su conjunto se ha formado y cómo va cambiando. El objetivo último de todo este proceso es llegar a formular las leyes que dictan la evolución del Universo.\n",
    "\n",
    "Para este trabajo se ha seleccionado un conjunto de datos perteneciente a un proyecto llamado **Galaxy Zoo**. A lo largo de este módulo final desarrollaremos los pasos para analizar éstos datos con una gran parte de las herramientas Big Data que hemos aprendido en módulos anteriores, y que sin duda nos ayudará a explorar y conocer el Universo en el que vivimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='astro' />\n",
    "\n",
    "### Astronomía y Big Data\n",
    "\n",
    "Potentes telescopios escanean el cielo y recogen fotos en formato digital de estrellas y galaxias lejanas. Son capaces de recoger imágenes de objetos celestes que a simple vista no podríamos observar. Aún así solo tenemos información de una pequeña fracción de la enorme cantidad (centenares de miles de millones) de galaxias que pueblan nuestro Universo. La Cosmología es la ciencia que estudia cómo el Universo ha nacido y evolucionado y tiene como objetivo entender cuál podría ser su destino. Conocer los distintos tipos de galaxias y clasificar su forma es uno de los pasos fundamentales para el avance en el conocimiento del Universo en que vivimos.\n",
    "\n",
    "La clasificación de imágenes de galaxias basada en su forma es el objetivo final de este trabajo. Para alcanzarlo tendremos que aplicar algunas de la técnicas de análisis y clasificación Big Data que hemos aprendido durante este curso.\n",
    "\n",
    "<div id='galaxias' />\n",
    "\n",
    "### Las Galaxias\n",
    "\n",
    "El Sol es una de las muchas estrellas que forman parte de nuestra galaxia: la Vía Láctea. Observando las estrellas más lejanas podemos ver cómo se agrupan formando galaxias de distintas forma y tamaño. Su forma, tamaño y brillo nos revelan cómo se forman y cómo evolucionan. Existen muchas maneras de clasificar las galaxias, por ejemplo por el color o el brillo, pero la más común es por su foma, que depende de su edad, composición, etc. \n",
    "\n",
    "Clasificar una galaxia por su forma no es siempre tarea fácil. Los tipos más reconocibles de galaxias son las espirales y las elípticas pero hay muchísimos estados intermedios, algunas con forma irregular que, junto con el tamaño, la orientación del objeto y la resolución de la imagen, pueden dificultar el trabajo del clasificador. Al contrario que el color, el brillo o la distancia, que son propiedades cuantitativas y pueden medirse de manera directa, la forma es mucho más difícil de valorar y depende de criterios más subjetivos.\n",
    "\n",
    "Según el **esquema de Hubble** o **diagrama diapasón**, como también se le suele llamar, podemos hacer la siguiente clasificación:\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/hubble.png\">\n",
    "\n",
    "---\n",
    "\n",
    "<div id='e07' />\n",
    "\n",
    "#### Galaxias elípticas (E0-7) \n",
    "\n",
    "Tienen forma elíptica, con una distribución bastante uniforme de las estrellas por todas partes. El número indica el grado de excentricidad: las galaxias E0 son casi redondas, mientras E7 son muy aplanadas. El número indica solo la apariencia de la galaxia en el cielo, no su geometría real.\n",
    "\n",
    "<div id='s0' />\n",
    "\n",
    "#### Galaxias lenticulares (S0 y SB0) \n",
    "\n",
    "Parecen tener una estructura de disco con una concentración de estrellas central proyectándose de él. No muestran ninguna estructura espiral.\n",
    "\n",
    "<div id='sa' />\n",
    "\n",
    "#### Galaxias espirales (Sa-d) \n",
    "\n",
    "Tienen una concentración de estrellas central y un disco aislado que presenta brazos espirales. Los brazos están centrados alrededor de la protuberancia, variando de los muy arremolinados y poco definidos (Sa) a los muy sueltos y definidos (Sc y Sd). Así mismo, mientras que en las primera la concentración central es muy pronunciada, en estos últimos lo es bastante menos, y (salvo excepciones) la cantidad de estrellas jóvenes y la proporción de gas van aumentando a lo largo de la secuencia.\n",
    "\n",
    "<div id='sb0/ad' />\n",
    "\n",
    "#### Galaxias espirales barradas (SB0/a-d) \n",
    "\n",
    "Tienen una estructura en espiral, similar a las galaxias espirales pero los brazos se proyectan desde el final de una \"barra\" central en lugar de emanar de una concentración central. De nuevo, SBa a SBd indica como de arremolinados están estos brazos y el grado de desarrollo de la concentración central y (de nuevo y salvo excepciones) la cantidad de gas y estrellas jóvenes va aumentando al ir progresando en la secuencia.\n",
    "\n",
    "<div id='sab0' />\n",
    "\n",
    "#### Galaxias espirales intermedias (SAB0/a-c) \n",
    "\n",
    "Tienen una morfología intermedia entre las galaxias espirales y las galaxias espirales barradas.\n",
    "\n",
    "<div id='irr' />\n",
    "\n",
    "#### Galaxias irregulares (Irr) \n",
    "\n",
    "Se dividen en Irr-I, que muestran estructura espiral deformada, e Irr-II para las galaxias que no encajan en ninguna otra categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='zoo' />\n",
    "\n",
    "### Galaxy Zoo\n",
    "\n",
    "El proyecto Galaxy Zoo consiste en recolectar datos sobre la forma del mayor número posible de objetos celestes. Para llevar a cabo esa tarea el proyecto cuenta con la colaboración de voluntarios que, a través de una página web, visualizan las imágenes de galaxias en su ordenador personal y clasifican el objeto fotografiado. El resultado se envía a través de la misma página web.\n",
    "\n",
    "En la página de [GalaxyZoo](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/) se puede acceder a un tutorial en inglés donde se explican los objetos representados en las imágenes y los criterios para llevar a cabo la clasificación.\n",
    "\n",
    "- Una galaxia *ELÍPTICA*, cuyo brillo va disminuyendo gradualmente desde el centro de la imagen.\n",
    "\n",
    "<img src=\"../images/eliptica.png\">\n",
    "\n",
    "- La imagen tiene estructuras que pueden ser:\n",
    "    - Los brazos de una galaxia *ESPIRAL*.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    <img src=\"../images/espiral.png\">\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    - Un núcleo, o unas barras, u otras características peculiares.\n",
    "    \n",
    "    ---\n",
    "\n",
    "    <img src=\"../images/otras1.png\">\n",
    "\n",
    "    <img src=\"../images/otras2.png\">\n",
    "    \n",
    "    ---\n",
    "   \n",
    "    - Una estrella, una traza de satélite o algún otro artefacto que obstaculice la posibilidad de clasificar el objeto.\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    <img src=\"../images/erronea1.png\">\n",
    "\n",
    "    <img src=\"../images/erronea2.png\">\n",
    "    \n",
    "    ---\n",
    "    \n",
    "En el proyecto GalaxyZoo original los voluntarios tenían que distinguir entre objetos elípticos, espiral horaria, espiral antihoraria, casos intermedios, estrella no identificable o fusión de objetos. Para este proyecto vamos a adoptar una versión de clasificación más simple ya que únicamente distinguiremos los objetos de forma elíptica. Dicho de otra forma, distinguiremos entre objetos sin estructura y objetos con forma espiral.\n",
    "\n",
    "<div id='sdss' />\n",
    "\n",
    "###  Sloan Digital Sky Survey\n",
    "\n",
    "Las imágenes son tomadas por los telescopios de un proyecto llamado Sloan Digital Sky Survey (SDSS). Al visitar la [web](https://www.sdss.org/) del proyecto tendremos acceso a los datos así como a un repositorio extenso de documentación y herramientas sobre astronomía (y el proyecto SDSS en particular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='herramientas' />\n",
    "\n",
    "## Herramientas Cloudera\n",
    "\n",
    "Con la idea de presentar un proyecto Big Data de principio a fin hemos decidido que para el desarrollo de este trabajo usaremos las siguientes herramientas.\n",
    "\n",
    "#### Docker - Cloudera\n",
    "\n",
    "Se ha optado por configurar un contenedor *Docker* corriendo la versión **cloudera-quickstart-vm-5.13.0**. La elección de docker frente a una máquina virtual se basa en su facilidad de despliegue, configuración, portabilidad y la posibilidad de aprovechar los recursos de la máquina host al máximo, que en nuestro caso se trata de un portátil de 8 cores y 16GB RAM.\n",
    "\n",
    "#### HDFS\n",
    "\n",
    "HDFS y sus comandos de consola para el almacenamiento y la ingestión de datos.\n",
    "\n",
    "#### HIVE - IMPALA - HUE\n",
    "\n",
    "Herramientas para la creación del modelo de datos, la importación de los datos externos, su exploración preliminar y su análisis posterior.\n",
    "\n",
    "#### SPARK - Anaconda\n",
    "\n",
    "Notebooks de pyspark para el desarrollo de algoritmos, análisis, visualización e interpretación de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='conf' />\n",
    "\n",
    "## Configuración Cloudera\n",
    "\n",
    "Nota: a partir de ahora seguiremos la siguiente nomenclatura para la escritura en consola.\n",
    "\n",
    "~~~\n",
    "$ se refiere a comandos a ejecutar en la máquina (host) que aloja nuestro contenedor.\n",
    "[container]$ indica comandos a ejecutar en la shell de nuestro contenedor como usuario root (si no se indi- ca lo contrario)\n",
    "[hive]$ [spark2]$ [etc]$ -> otras alternativas dependiendo del entorno dentro de nuestro contenedor.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='docker' />\n",
    "\n",
    "#### Imagen y contenedor Docker\n",
    "\n",
    "Empezaremos la configuración de nuestro entorno partiendo del hecho de que *Docker* ya se encuentra instalado y totalmente configurado, por lo tanto procedemos a descargar la imagen de *Cloudera* directamente desde sus repositorios.\n",
    "\n",
    "\n",
    "`\n",
    "$ wget https://downloads.cloudera.com/demo_vm/docker/cloudera-quickstart-vm-5.13.0-0-beta-docker.tar.gz\n",
    "$ tar xzf cloudera-quickstart-vm-*-docker.tar.gz\n",
    "$ docker import cloudera-quickstart-vm-5.13.0–0-beta-docker.tar\n",
    "$ docker tag <image_name> cloudera/quickstart:5.13.0\n",
    "`\n",
    "\n",
    "\n",
    "Una vez importada la imagen pasamos a arrancar nuetro contenedor mediante el comando `run`. \n",
    "\n",
    "- --name indica el nombre del contenedor.\n",
    "- --hostname indica el nombre del host.\n",
    "- --privileged=true para que nuestro contenedor tenga permisos sobre nuestra máquina.\n",
    "- --publish-all=true para exponer todos los puertos.\n",
    "- -p mapea los puertos de nuestro host con los del contenedor.\n",
    "\n",
    "\n",
    "`\n",
    "$ docker run -d -i -t --name cloudera-spark2-anaconda --hostname=quickstart.cloudera --privileged=true --publish all=true -p 10002:10002 -p 55489:55489 -p 8888:8888 -p 10000:10000 -p 10020:10020 -p 11000:11000 -p 18080:18080 -p 18081:18081 -p 18088:18088 -p 19888:19888 -p 21000:21000 -p 21050:21050 -p 2181:2181 -p 25000:25000 -p 25010:25010 -p 25020:25020 -p 50010:50010 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 60000:60000 -p 60010:60010 -p 60020:60020 -p 60030:60030 -p 7180:7180 -p 7183:7183 -p 7187:7187 -p 80:80 -p 8020:8020 -p 8032:8032 -p 8042:8042 -p 8088:8088 -p 8983:8983 -p 9083:9083 -p 8889:8889 cloudera-spark2-anaconda/quickstart:5.13.0 /usr/bin/docker-quickstart\n",
    "`\n",
    "\n",
    "Una vez nuestro contenedor se encuentre en ejecución podremos acceder mediante el comando \n",
    "\n",
    "`\n",
    "$ docker exec -it cloudera-spark2-anaconda bash\n",
    "`\n",
    "\n",
    "<div id='pkt' />\n",
    "\n",
    "#### Instalación de paquetes\n",
    "\n",
    "Antes que nada instalaremos una serie de paquetes necesarios para llevar a cabo la configuración.\n",
    "\n",
    "<div id='wget' />\n",
    "\n",
    "##### wget\n",
    "\n",
    "Necesario para la descarga de paquetes desde consola.\n",
    "\n",
    "`\n",
    "[container]$ yum install wget\n",
    "`\n",
    "\n",
    "<div id='manager' />\n",
    "\n",
    "###### Cloudera Manager\n",
    "\n",
    "Cloudera Manager es una plataforma de administración de Cloudera open source, para la gestión de clusters HADOOP. Este tipo de frameworks facilitan la gestión manual que supone la administración de un clúster, ya que se trata de un trabajo complicado y bastante propenso a errores. Pensar en todos los pasos que hay que seguir en cada nodo: instalación del paquete de HADOOP, configuración de variables de entorno, definición de archivos de configuración, definir permisos y reglas de seguridad, levantar demonios, formateo del sistema HDFS, etc. \n",
    "\n",
    "Cloudera Manager no viene activa por defecto:\n",
    "\n",
    "`\n",
    "[container]$ service cloudera-scm-server status\n",
    "`\n",
    "\n",
    "Lo cual nos pedirá ejecutar el siguiente comando:\n",
    "\n",
    "`\n",
    "[container]$ /home/cloudera/cloudera-manager --express\n",
    "`\n",
    "\n",
    "La opción `--express` indica que vamos a instalar la versión Cloudera Express (free). Para instalar la versión Enterprise debemos seleccionar la opción `--enterprise`. Finalizado el proceso podemos acceder a la interfaz web http://localhost:7180 con el usuario/contraseña por defecto *cloudera*.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera-manager.png\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='anaconda' />\n",
    "\n",
    "##### Anaconda\n",
    "\n",
    "Instalaremos Anaconda como entorno principal para la analítica de datos. Hay que mencionar que la versión de Python instalada por defecto en el sistema **cloudera-quickstart-vm-5.13.0** es la 2.6. Con la instalación de Anaconda se instalará en paralelo Python 3.7.\n",
    "\n",
    "En primer lugar crearemos un directorio de trabajo donde escribiremos el siguiente script de instalación llamado `setup_pyspark.sh`\n",
    "\n",
    "`\n",
    "[container]$ mkdir /home/cloudera/galaxias\n",
    "[container]$ vim setup_pyspark.sh\n",
    "`\n",
    "\n",
    "~~~\n",
    "#!/bin/bash\n",
    "\n",
    "ANACONDA_FILE=Anaconda3-2020.02-Linux-x86_64.sh\n",
    "ANACONDA_LOCAL_FILE=/tmp/$ANACONDA_FILE\n",
    "ANACONDA_REMOTE_FILE=https://repo.anaconda.com/archive/$ANACONDA_FILE\n",
    "ANACONDA_MD5=17600d1f12b2b047b62763221f29f2bc\n",
    "\n",
    "# Download and install Anaconda\n",
    "CONDA_VERSION=$(conda --version 2> /dev/null)\n",
    "if [ \"$CONDA_VERSION\" != \"conda 4.2.9\" ]\n",
    "then\n",
    "  curl -o $ANACONDA_LOCAL_FILE $ANACONDA_REMOTE_FILE\n",
    "  FILE_MD5=$(md5sum $ANACONDA_LOCAL_FILE | awk '{print $1}')\n",
    "  if [ \"$ANACONDA_MD5\" != \"$FILE_MD5\" ]\n",
    "  then\n",
    "      echo \"Download of file: $ANACONDA_FILE failed, try again\"\n",
    "      rm $ANACONDA_FILE\n",
    "      exit 1\n",
    "  fi\n",
    "  bash $ANACONDA_LOCAL_FILE\n",
    "  rm -f $ANACONDA_LOCAL_FILE\n",
    "  \n",
    "  # Add environment variables to .bashrc\n",
    "  if ! grep -Fq \"PYSPARK_DRIVER_PYTHON=\" ~/.bashrc\n",
    "  then\n",
    "    echo 'export PYSPARK_DRIVER_PYTHON=jupyter' >> ~/.bashrc\n",
    "  fi\n",
    "  if ! grep -Fq \"PYSPARK_DRIVER_PYTHON_OPTS=\" ~/.bashrc\n",
    "  then\n",
    "    echo \"export PYSPARK_DRIVER_PYTHON_OPTS='notebook --allow-root --ip=0.0.0.0 --port=55489 --notebook-dir=/home/cloudera/galaxias'\" >> ~/.bashrc\n",
    "  fi\n",
    "else\n",
    "  echo \"Anaconda already installed and at the convenient version\"\n",
    "fi\n",
    "\n",
    "# Source .bashrc to set environement variables and add Anaconda binaries to path\n",
    ". ~/.bashrc\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "Con dicho script instalamos Anaconda3 y configuramos las variables de entorno que servirán de conector con SPARK (PYSPARK_DRIVER_PYTHON y PYSPARK_DRIVER_PYTHON_OPTS). Básicamente indicamos que se inicie SPARK en un notebook de jupyter en localhost en el puerto 55489 y que nuestro directorio raíz de trabajo sea `home/cloudera/galaxias`. \n",
    "\n",
    "Podemos elegir otro puerto sobre el que ejecutar nuestro notebook. El único requisito a tener en cuenta es que no puede ser alguno de los ya utilizados por Cloudera. De no indicar esta opción, no podríamos arrancar nuestros notebooks ya que el puerto por defecto 8888 entraría en conflicto con el de HUE. Además, debemos tener en cuenta estas circunstancias a la hora de arrancar nuestro contenedor pues todos los puertos a los que posteriormente accederemos deberán de estar expuestos hacia el host (esto es con la opción `-p` del comando `docker run`).\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/anaconda_install_1.png\">\n",
    "\n",
    "<img src=\"../images/anaconda_install_2.png\">\n",
    "\n",
    "<img src=\"../images/anaconda_install_3.png\">\n",
    "\n",
    "<img src=\"../images/anaconda_install_4.png\">\n",
    "\n",
    "<img src=\"../images/anaconda_install_5.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Y nuestro `~/.bashrc` quedaría tal que:\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/bashrc.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Por último, podríamos exportar el directorio de Anaconda al PATH de `~/.bash_profile` tal como se muestra en la imagen de la siguiente sección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='java8' />\n",
    "\n",
    "###### Java 8 JDK\n",
    "\n",
    "La versión de java instalada por defecto es la 1.7. Para instalar SPARK2 debemos instalar la versión 1.8 o superior. En nuestro caso instalaremos la versión 8 ya que puede coexistir junto a la versión 1.7 (no será necesario desinstalarla). Debemos parar los servicios de Clodera Manager antes de hacer la instalación.\n",
    "\n",
    "`\n",
    "[container]$ service cloudera-scm-server stop\n",
    "[container]$ service cloudera-scm-agent stop\n",
    "[container]$ java -version\n",
    "java version \"1.7.0_67\"\n",
    "Java(TM) SE Runtime Environment (build 1.7.0_67-b01)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)\n",
    "[container]$ which java\n",
    "/usr/bin/java\n",
    "[container]$ cd /usr/java/\n",
    "[container]$ wget https://download.java.net/openjdk/jdk8u41/ri/openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz\n",
    "[container]$ tar xvf openjdk-8u41-b04-linux-x64-14_jan_2020.tar.gz\n",
    "[container]$ mv java-se-8u41-ri/ java8\n",
    "`\n",
    "\n",
    "Con esto tenemos la versión de java 1.8 disponible dentro del directorio `/usr/java/java8`. Ahora añadiremos las variables de entorno a nuestro archivo `~/.bash_profile`. Debería quedar así:\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/bash_profile.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Además debemos exportar la nueva configuración JDK al Cloudera Manager Server. Al final del archivo `/etc/default/cloudera-scm-server` escrimos la siguiente sentencia `export JAVA_HOME=/usr/java/java8`\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/java_scm.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Para finalizar reiniciamos nuestra configuracion e iniciamos los servicios.\n",
    "\n",
    "`\n",
    "[container]$ . ~/.bash_profile\n",
    "[container]$ java -version\n",
    "openjdk version \"1.8.0_41\"\n",
    "OpenJDK Runtime Environment (build 1.8.0_41-b04)\n",
    "OpenJDK 64-Bit Server VM (build 25.40-b25, mixed mode)\n",
    "[container]$ service cloudera-scm-server start\n",
    "[container]$ service cloudera-scm-agent start\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='spark2' />\n",
    "\n",
    "##### Spark2\n",
    "\n",
    "Para instalar SPARK2 debemos entender el concepto de *parcel*. Los parcels son paquetes de software distribuidos por Cloudera Manager, de tal manera que a través de la propia interfaz de Cloudera Manager podemos descargar, distribuir y activar nuevo software. En definitiva, los parcels contienen los binarios necesarios que serán usados por Cloudera Manager para desplegar el nuevo software en nuestro clúster.\n",
    "\n",
    "Para nuestro caso de uso instalaremos la versión 2.4 release 2 (SPARK2_ON_YARN-2.4.0.cloudera2.jar). Podemos encontras más información en los siguientes enlaces:\n",
    "\n",
    "- [CDS Powered by Apache Spark](https://docs.cloudera.com/documentation/spark2/latest/topics/spark2_installing.html)\n",
    "- [CDS Powered by Apache Spark Requirements](https://docs.cloudera.com/documentation/spark2/latest/topics/spark2_requirements.html)\n",
    "- [Download Information](https://docs.cloudera.com/documentation/spark2/latest/topics/spark2_packaging.html#versions)\n",
    "\n",
    "`\n",
    "[container]$ cd /opt/cloudera/csd/\n",
    "[container]$ wget http://archive.cloudera.com/spark2/csd/SPARK2_ON_YARN-2.4.0.cloudera2.jar\n",
    "[container]$ chown cloudera-scm:cloudera-scm SPARK2_ON_YARN-2.4.0.cloudera2.jar\n",
    "[container]$ chmod 644 SPARK2_ON_YARN-2.4.0.cloudera2.jar\n",
    "`\n",
    "\n",
    "Asignamos el fichero al usuario 'cloudera' y le damos permisos 644 para que sea manipulado por Cloudera Manager. \n",
    "\n",
    "A continuación nos vamos a http://localhost:7180 donde navegaremos hasta la sección `Hosts/AllHosts`. Seleccionamos la pestaña *Configuration*\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_1_allhosts.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Buscamos *java* en el recuadro de búsqueda y ponemos el directorio de instalación de java `/usr/java/java8`.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_2_java.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Navegamos a `Hosts/Parcels` y volvemos a seleccionar la pestaña *Configuration*. Bajamos hasta el final y quitamos la pestaña *Validate Parcel Relations*.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_4_parcels.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Reiniciamos los servicios para aplicar la nueva configuración.\n",
    "\n",
    "`\n",
    "[container]$ service cloudera-scm-agent restart\n",
    "[container]$ service cloudera-scm-server restart\n",
    "`\n",
    "\n",
    "Al volver a la sección de *Parcels* dentro de Cloudera Manager vemos que se ha tenido que añadir el parcel relativo a SPARK2. Lo descargamos y lo activamos.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_5_down_spark2.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_6_distribute_spark2.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_7_act_spark2.png\">\n",
    "    \n",
    "---\n",
    "\n",
    "Repetimos el procedimiento con el parcel CDH 5 para poder desplegar en el clúster (incluso aunque nuestro entorno sea un contenedor docker standalone).\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_10_act_cdh.png\">\n",
    "\n",
    "---\n",
    "\n",
    "En el dashboard principal (izquierdo) *Cloudera QuickStart (CDH 5.13.0, Parcels)* añadimos el servicio SPARK2 y seleccionamos todas sus dependencias y los nodos sobre los que aplicar.\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_11_add_service.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_12_add_spark2.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_13_add_spark2.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_14_select_host.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_15_add_spark2.png\">\n",
    "\n",
    "<img src=\"../images/cloudera_16_add_spark2.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Finalmente reiniciamos Cloudera Manager y desplegamos la nueva configuración.\n",
    "\n",
    "`\n",
    "[container]$ service cloudera-scm-agent restart\n",
    "[container]$ service cloudera-scm-server restart\n",
    "`\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"../images/cloudera_17_deploy_client_conf.png\">\n",
    "\n",
    "---\n",
    "\n",
    "Una vez terminado todo el proceso podemos ir a nuestra consola y comprobar que la instalación ha sido correcta:\n",
    "\n",
    "`\n",
    "[container]$ pyspark2 --version\n",
    "`\n",
    "~~~\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  ._/\n",
    "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.0.cloudera2\n",
    "      /_/\n",
    "                        \n",
    "Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_41\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y para finalizar podremos ejecutar nuestro jupyter notebook automáticamente tecleando en consola `pyspark2`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
